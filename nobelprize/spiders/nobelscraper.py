import scrapy
from scrapy.selector import Selector

# The class "Nobel" creates all fields which later will be used as a header for the table
class Nobel(scrapy.Item):
    d = {} # create a dictionary

    # Create all scrapy fields we want to scrape for all pages
    # Add labels of values that appear on every page (like year, identification number, url of the page)
    d["A0_year"] = scrapy.Field()
    d["A1_number"] = scrapy.Field()
    d["A2_url"] = scrapy.Field()
    d["A3_comments"] = scrapy.Field()

    # "numNominees" is the maximum amount of nominees occurring on a single page
    numNominees = 3
    # "maxNuminators" is the maximum amount of nominators occurring on a single page
    numNominators = 21
    character = 66 # ASCII code for the char "B", this number will be incremented for each iteration in the for-loops.

    # Calculate Nominee-fields

    # for-loop: i = 1; i<(numNominees + 1) (this equals: i<=numNominees)
    for i in range(1, numNominees + 1):

        # Set counter to zero
        count = 0

        # The label of the scrapy field is generated by [Character][Count]"_nominee_"[Label]
        # "Character" is explicitly type casted into a char, e.g. int 66 -> char 'B'
        # "Count" will be increased by one with each newly added scapy field (see count =+ 1)
        # "Labels" are "name", "gender", "birth" etc.
        d[chr(character)+str(count)+"_nominee"+str(i)+"_name"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominee"+str(i)+"_gender"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominee"+str(i)+"_birth"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominee"+str(i)+"_death"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominee"+str(i)+"_profession"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominee"+str(i)+"_city"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominee"+str(i)+"_country"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominee"+str(i)+"_motivation"] = scrapy.Field()

        # character will be increased for each iteration
        character = character + 1


    # Calculate Nominators
    # Same procedure as above, there are only some different labels (like "university") and the for-loop has
    # a different limit (numNominators)
    for i in range(1, numNominators + 1):
        count = 0
        d[chr(character)+str(count)+"_nominator"+str(i)+"_name"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominator"+str(i)+"_gender"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominator"+str(i)+"_birth"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominator"+str(i)+"_death"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominator"+str(i)+"_profession"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominator"+str(i)+"_university"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominator"+str(i)+"_city"] = scrapy.Field()
        count =+ 1
        d[chr(character)+str(count)+"_nominator"+str(i)+"_country"] = scrapy.Field()
        character = character + 1

# The class Categories is used to link the unique item label to a matching string and a lower and upper boundary to
# define an area we want to search in
class Categories(scrapy.Item):
    # The class consists of four fields per instance

    # "item_name" matches the label created in the class "Nobel"
    item_name = scrapy.Field()

    # A string which is used to identify the scraped field, for example if we want to find the name of an nominator we
    # can look for the string "Name:"
    string = scrapy.Field()

    # A lower and upper boundary where to look in. We need such a boundary because some strings occur more than one
    # time on a page. The best example is the string "Name:", a nominator but also a nominee have a name. Therefore we
    # must specify where to look for this string ("Name:")

    # Initializing the lower boundary "start"
    start = scrapy.Field()

    # Initializing the upper boundary "end"
    end = scrapy.Field()

    # This method "generateField" generates a field and returns the generated field
    def generateField(self):

        # Generate an empty field
        field = []

        # Add fields that are only occurring once
        # "A2_url" is not in this list, because it will be extracted separately
        # start = "1", because it should search from the first td element in the table until the last td element
        # (end = "last", "last" is a reserved word in xpath to always find the last child of multiple html-tags)
        field.append(Categories(item_name = "A0_year", string = "Year:", start = "1", end = "last"))
        field.append(Categories(item_name = "A1_number", string = "Number:", start = "1", end = "last"))
        field.append(Categories(item_name = "A3_comments", string = "Comments:", start = "1", end = "last"))

        # Load settings from Nobel class
        numNominees = Nobel.numNominees
        numNominators = Nobel.numNominators
        character = 66 # ASCII code for the char "B", this number will be incremented for each iteration in the for-loops.

        # The for-loops work similar to the for-loops in "Nobel"
        # Only the differences are commented

        # Calculate Nominees
        for i in range(1, numNominees + 1):
            count = 0
            # For the first iteration the lower border should be "Nominee:" and the upper border should be "Nominator:"
            # because in this case we are assuming there is only one Nominee and therefore the string has no number.
            # This assumption will later be revisited.
            if i == 1:
                startString = "Nominee:"
                endString = "Nominator:"
            # For all other cases we are assuming there are multiple Nominees, the lower border is
            # "Nominee "[Iteration]":" and the upper border is "Nominee "[Iteration + 1]":"
            # For now we are assuming if there exists a "Nominee 2:" a "Nominee 3:" also exists
            else:
                startString = "Nominee " + str(i) + ":"
                endString = "Nominee " + str(i+1) + ":"
            field.append(Categories(item_name = chr(character)+str(count)+"_nominee"+str(i)+"_name", string = "Name:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominee"+str(i)+"_gender", string = "Gender:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominee"+str(i)+"_birth", string = "Year, Birth:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominee"+str(i)+"_death", string = "Year, Death:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominee"+str(i)+"_profession", string = "Profession:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominee"+str(i)+"_city", string = "City:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominee"+str(i)+"_country", string = "Country:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominee"+str(i)+"_motivation", string = "Motivation:", start = startString, end = endString))
            character = character + 1

        # Calculate Nominators
        # Same procedure as above
        for i in range(1, numNominators + 1):
            count = 0
            if i == 1:
                startString = "Nominator:"
                endString = "last"
            else:
                startString = "Nominator " + str(i) + ":"
                endString = "Nominator " + str(i+1) + ":"
            field.append(Categories(item_name = chr(character)+str(count)+"_nominator"+str(i)+"_name", string = "Name:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominator"+str(i)+"_gender", string = "Gender:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominator"+str(i)+"_birth", string = "Year, Birth:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominator"+str(i)+"_death", string = "Year, Death:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominator"+str(i)+"_profession", string = "Profession:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominator"+str(i)+"_university", string = "University:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominator"+str(i)+"_city", string = "City:", start = startString, end = endString))
            count = count + 1
            field.append(Categories(item_name = chr(character)+str(count)+"_nominator"+str(i)+"_country", string = "Country:", start = startString, end = endString))
            character = character + 1

        # Return the generated field
        return field

# Class of the spider
class NobelSpider(scrapy.Spider):

    # Name of the spider
    name = "nobelscraper"

    # Comment out; Import URLs from a txt file
    # f = open("urls.txt",'r')
    # start_urls = [url.strip() for url in f.readlines()]
    # f.close()

    # Urls for debugging
    # The first url is very prototypical: it contains only one nominee and one nominator
    # The second url contains 3 nominees and only one nominator
    # The third url contains many nominators but only one nominee

    start_urls = [
        'http://www.nobelprize.org/nomination/archive/show.php?id=5469',
        'http://www.nobelprize.org/nomination/archive/show.php?id=17599',
        'http://www.nobelprize.org/nomination/archive/show.php?id=1046'
    ]

    def parse(self, response):
        # Load settings from the Nobel class
        numNominees = Nobel.numNominees
        numNominators = Nobel.numNominators

        # Import field from Categories
        field = Categories.generateField(self)

        # Import items, this will be used as the header of our table
        item = Nobel.d

        # Shortcut to select the response
        sel = Selector(response)

        # String which is added to an item if this item doesn't exist on the page
        elseCase = "None"

        # Loop through all fields in the field array
        for i in range(0, len(field)):
            # Set upper and lower boundries
            start = field[i].get("start")
            end = field[i].get("end")

            ####### MULTIPLE NOMINEES
            # Check if the lower border is "Nominee:" and if there exists a string named "Nominee 1:"
            if start == "Nominee:" and sel.xpath('//tr//td[.="Nominee 1:"]'):
                # This means the string "Nominee:" doesn't exist on the page and the lower border should therefore
                # be changed to "Nominee 1:"
                start = "Nominee 1:"

                # Now check if there exists a string named "Nominee 2:", this indicates that there is a second nominee.
                # The default upper boundary for the first Nominee ("Nominator") should therefore be changed to
                # "Nominee 2:"
                if sel.xpath('//tr//td[.="Nominee 2:"]'):
                    end = "Nominee 2:"

            # Like I said in the "Categories" class I am assuming if there exists a string "Nominators 2:" the string
            # "Nominators 3:" must also exist. This is of course a false assumption. Therefore we must check for each
            # Nominee if the upper boundary really exist. If this is not the case we must change the upper boundary
            # to "Nominator:" if there is only one nominator, if there are multiple nominators it should be changed to
            # "Nominator 1:".
            count = 1;
            for x in range (1, numNominees + 1):
                if sel.xpath('//tr//td[.="Nominee '+str(x)+':"]'):
                    count = 1 + count
            if end == "Nominee " + str(count) + ":" and start == "Nominee " + str(count-1) + ":":
                if sel.xpath('//tr//td[.="Nominator:"]'):
                    end = "Nominator:"
                elif sel.xpath('//tr//td[.="Nominator 1:"]'):
                    end = "Nominator 1:"

            ####### MULTIPLE NOMINATORS
            # This code works following the same mechanism as above:
            if sel.xpath('//tr//td[.="Nominator 1:"]'):
                if start == "Nominator:":
                    start = "Nominator 1:"
                    if sel.xpath('//tr//td[.="Nominator 2:"]'):
                        end = "Nominator 2:"
                if end == "Nominator:":
                    end = "Nominator 1:"

            # The only difference is that if there is no following "Nominator "[x]":" the upper boundary should be set
            # to "last", a.k.a. the last td-child
            count = 1;
            for x in range (1, numNominators + 1):
                if sel.xpath('//tr//td[.="Nominator '+str(x)+':"]'):
                    count = 1 + count
            if end == "Nominator " + str(count) + ":" and start == "Nominator " + str(count-1) + ":":
                end = "last"

            # Calculate a prefix which defines the area on the web page we want to look for a string
            # If the lower boundary != 1 we have to calculate the position of our td-tag containing our string compared
            # to the first td-child, e.g. the name of the nominee is usually the 4th td-tag
            if not start == "1":
                start = 'count(//tr/td[.="' + start+ '"]/../preceding-sibling::*)+1'

            # Do the same for the lower boundary
            if not end =="last":
                end = 'count(//tr/td[.="' + end+ '"]/../preceding-sibling::*)+1'

            # Generate the prefix
            prefix = '//tr[position()>=' + start + ' and not (position()>' + end + ')]'

            # The xpath is the path to the string we want to look for within the area we defined in prefix
            xpath = prefix + '/td[.="' + field[i].get("string") + '"]//following-sibling::td//text()'

            # List selects this path
            list = sel.xpath(xpath).extract()

            # Now check if there exists the given string within the defined area
            # If this is the case, extract the data and add it to the item
            if list:
                item[field[i].get("item_name")] = ''.join(sel.xpath(prefix + '/td[.="'+field[i].get("string")+'"]//following-sibling::td[1]//text()').extract()).replace('\r', '').replace('\n', '')

            # If this is not the case set a default value. I added a default value so you can trace if you missed some
            # values
            else:
                item[field[i].get("item_name")] = elseCase

        # Add a url of the original page to backtrace the scraped page
        item["A2_url"] = response.url

        # Add items to the table
        yield item
